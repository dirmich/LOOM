#!/usr/bin/env python3
"""
v3 ë””ì½”ë” ì‹¤íŒ¨í•œ 16ê°œ ì˜¤ë¸Œì íŠ¸ ìƒì„¸ ë¶„ì„
"""
import json
from pathlib import Path
from collections import Counter


def xor_decrypt(data):
    """XOR 0xFF ë³µí˜¸í™”"""
    return bytearray([b ^ 0xFF for b in data])


def analyze_remaining_failures():
    """v3ì—ì„œ ì‹¤íŒ¨í•œ 16ê°œ ì˜¤ë¸Œì íŠ¸ ë¶„ì„"""

    # objects_analysis.json ì½ê¸° (ì „ì²´ 248ê°œ)
    with open('analyze/objects_analysis.json', 'r') as f:
        analysis = json.load(f)

    # objects_png_v3_results.json ì½ê¸° (ì„±ê³µí•œ 111ê°œ)
    with open('analyze/objects_png_v3_results.json', 'r') as f:
        v3_results = json.load(f)

    # ì„±ê³µí•œ ì˜¤ë¸Œì íŠ¸ ID ìˆ˜ì§‘
    successful_ids = set()
    for obj in v3_results['objects']:
        successful_ids.add((obj['room'], obj['object_id']))

    print('ğŸ” v3 ë””ì½”ë” ì‹¤íŒ¨í•œ ì˜¤ë¸Œì íŠ¸ ìƒì„¸ ë¶„ì„')
    print('=' * 70)
    print(f'\nì´ ì˜¤ë¸Œì íŠ¸: {v3_results["stats"]["total"]}ê°œ')
    print(f'ì„±ê³µ: {v3_results["stats"]["success"]}ê°œ')
    print(f'ë¹ˆ ì˜¤ë¸Œì íŠ¸: {v3_results["stats"]["empty"]}ê°œ')
    print(f'ë©”íƒ€ë°ì´í„°: {v3_results["stats"]["meta"]}ê°œ (19-byte)')
    print(f'ì‹¤íŒ¨: {v3_results["stats"]["failed"]}ê°œ')

    # ì‹¤íŒ¨í•œ ì˜¤ë¸Œì íŠ¸ ìˆ˜ì§‘
    failed_objects = []
    size_distribution = Counter()

    for room in analysis['rooms'][:5]:
        room_num = room['room']
        lfl_file = Path(f'{room_num}.LFL')

        if not lfl_file.exists():
            continue

        # LFL ì½ê¸°
        with open(lfl_file, 'rb') as f:
            encrypted = f.read()
        room_data = xor_decrypt(encrypted)

        for obj in room['objects']:
            obj_id = obj['id']
            obim_size = obj['obim_size']

            # ë¹ˆ ì˜¤ë¸Œì íŠ¸ ìŠ¤í‚µ
            if obim_size == 0:
                continue

            # 19-byte ë©”íƒ€ë°ì´í„° ìŠ¤í‚µ
            if obim_size == 19:
                continue

            # ì„±ê³µí•œ ì˜¤ë¸Œì íŠ¸ ìŠ¤í‚µ
            if (room_num, obj_id) in successful_ids:
                continue

            # ì‹¤íŒ¨í•œ ì˜¤ë¸Œì íŠ¸
            obim_offset = obj['obim_offset']
            obim_data = room_data[obim_offset:obim_offset + obim_size]

            failed_objects.append({
                'room': room_num,
                'object_id': obj_id,
                'size': obim_size,
                'offset': obim_offset,
                'data': obim_data
            })

            size_distribution[obim_size] += 1

    print(f'\n\nğŸ“¦ ì‹¤íŒ¨í•œ {len(failed_objects)}ê°œ ì˜¤ë¸Œì íŠ¸ ë¶„ì„')
    print('=' * 70)

    # í¬ê¸°ë³„ ë¶„í¬
    print('\ní¬ê¸°ë³„ ë¶„í¬:')
    for size, count in sorted(size_distribution.items()):
        print(f'   {size:5d} bytes: {count:3d}ê°œ')

    # ê° ì‹¤íŒ¨ ì˜¤ë¸Œì íŠ¸ ìƒì„¸ ë¶„ì„
    print('\n\nğŸ“‹ ì‹¤íŒ¨ ì˜¤ë¸Œì íŠ¸ ìƒì„¸ ë¶„ì„')
    print('-' * 70)

    for i, obj in enumerate(failed_objects):
        print(f"\n[{i}] Room {obj['room']}, Object {obj['object_id']} ({obj['size']} bytes)")
        print(f"    Offset: 0x{obj['offset']:04X}")

        data = obj['data']

        # Hex dump (ì²˜ìŒ 64 bytes)
        print(f"    Hex (ì²˜ìŒ 64 bytes):")
        for j in range(0, min(64, len(data)), 16):
            chunk = data[j:j+16]
            hex_str = ' '.join(f'{b:02X}' for b in chunk)
            print(f"       {j:04X}  {hex_str}")

        # ì—¬ëŸ¬ í—¤ë” í¬ê¸°ë¡œ strip offset íŒŒì‹± ì‹œë„
        print(f"\n    Strip offset íŒŒì‹± ì‹œë„:")

        for header_size in [0, 2, 4, 6, 8, 10, 12]:
            if header_size >= len(data):
                continue

            print(f"       Header {header_size} bytes:")
            offsets = []
            ptr = header_size

            for k in range(10):  # ìµœëŒ€ 10ê°œ stripë§Œ í™•ì¸
                if ptr + 1 >= len(data):
                    break
                offset = data[ptr] | (data[ptr+1] << 8)

                if offset == 0 or offset >= len(data):
                    break
                if offsets and offset <= offsets[-1]:
                    break
                if offset < header_size + 2:
                    break

                offsets.append(offset)
                ptr += 2

            if offsets:
                offset_str = ', '.join(f'0x{o:04X}' for o in offsets[:10])
                print(f"          Offsets: [{offset_str}]")
                print(f"          Count: {len(offsets)} strips")
            else:
                print(f"          âŒ ìœ íš¨í•œ offset ì—†ìŒ")

        # íŠ¹ìˆ˜ íŒ¨í„´ ê²€ì‚¬
        print(f"\n    íŒ¨í„´ ë¶„ì„:")

        # ëª¨ë“  ë°”ì´íŠ¸ê°€ 0ì¸ì§€
        if all(b == 0 for b in data):
            print(f"       âš ï¸  ëª¨ë‘ 0x00 (ë¹ˆ ë°ì´í„°)")

        # ë°˜ë³µ íŒ¨í„´
        if len(set(data[:16])) == 1:
            print(f"       âš ï¸  ë°˜ë³µ íŒ¨í„´: 0x{data[0]:02X}")

        # ASCII í…ìŠ¤íŠ¸?
        ascii_count = sum(1 for b in data[:32] if 32 <= b < 127)
        if ascii_count > 24:  # 75% ì´ìƒ
            ascii_text = ''.join(chr(b) if 32 <= b < 127 else '.' for b in data[:32])
            print(f"       ğŸ’¬ ASCII í…ìŠ¤íŠ¸ ê°€ëŠ¥ì„±: \"{ascii_text}\"")

    # JSONìœ¼ë¡œ ê²°ê³¼ ì €ì¥
    result_data = {
        'total_failed': len(failed_objects),
        'size_distribution': dict(size_distribution),
        'failed_objects': [
            {
                'room': obj['room'],
                'object_id': obj['object_id'],
                'size': obj['size'],
                'offset': obj['offset'],
                'hex_preview': obj['data'][:64].hex()
            }
            for obj in failed_objects
        ]
    }

    output_path = Path('analyze/remaining_failures.json')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, indent=2, ensure_ascii=False)

    print(f'\n\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}')
    print('=' * 70)


if __name__ == '__main__':
    analyze_remaining_failures()
